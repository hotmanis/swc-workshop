{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Basic Programming Using Python: Testing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Objectives"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Explain why it is not practical to prove a program correct by testing it.\n",
      "* Distinguish between pre-conditions, post-conditions, and invariants.\n",
      "* Correctly raise and handle exceptions.\n",
      "* Explain why exceptions are a better way to handle errors than special return codes.\n",
      "* Correctly write unit tests using an xUnit-style unit testing framework.\n",
      "* Name and explain the three types of results a test can produce.\n",
      "* Explain what test-driven development is, and use it to develop functions with well-specified behavior."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Setting Expectations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We created, found, and fixed over half a dozen bugs\n",
      "in our [previous lesson](python-4-files-lists.ipynb).\n",
      "How can we be sure that others aren't still lurking in our code?\n",
      "It's not an idle worry:\n",
      "every year,\n",
      "programmers find errors in software that has been in use for years,\n",
      "and the number of papers that have been retracted\n",
      "because of computational mistakes\n",
      "is constantly growing."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The short answer is that it's practically impossible to prove that a program will always do what it's supposed to.\n",
      "To see why,\n",
      "consider a function that checks whether a character strings contains only the letters 'A', 'C', 'G', and 'T'.\n",
      "These four tests clearly aren't sufficient:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "assert is_all_bases('A')\n",
      "assert is_all_bases('C')\n",
      "assert is_all_bases('G')\n",
      "assert is_all_bases('T')\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "because this version of `is_all_bases` passes them:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "def is_all_bases(bases):\n",
      "    return True\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Adding these tests isn't enough:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "assert not is_all_bases('X')\n",
      "assert not is_all_bases('Y')\n",
      "assert not is_all_bases('Z')\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "because this version still passes:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "def is_all_bases(bases):\n",
      "    return bases[0] in 'ACGT'\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can add yet more tests:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "assert is_all_bases('ACGCGA')\n",
      "assert not is_all_bases('CGAZ')\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "but no matter how many we have,\n",
      "we can always write a function that passes them,\n",
      "but does the wrong thing in other cases."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing is still worth doing, though:\n",
      "it's one of those things that doesn't work in theory,\n",
      "but is surprisingly effective in practice.\n",
      "If we choose our tests carefully,\n",
      "we can demonstrate that our software is as likely to be correct as a mathematical proof\n",
      "or a physical experiment."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ensuring that we have the right answer is only one reason to to software.\n",
      "The other is that it speeds up development\n",
      "by reducing the amount of re-work we have to do.\n",
      "Even small programs can be quite complex,\n",
      "and changing one thing can all too easily break something else.\n",
      "If we test changes as we make them,\n",
      "and automatically re-test things we've already done,\n",
      "we can catch and fix errors while the changes are still fresh in our minds."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Defensive Programming"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step is to use [defensive programming](glossary.html#defensive_programming),\n",
      "i.e.,\n",
      "to put assertions in our programs so that they check their own execution as they run.\n",
      "Programs like the Firefox browser are littered with assertions:\n",
      "10-20% of the code they contain\n",
      "are there to check that the other 80-90% are working correctly.\n",
      "Broadly speaking,\n",
      "assertions fall into three categories:\n",
      "\n",
      "- A [precondition](glossary.html#precondition) is something that must be true\n",
      "  in order for a piece of code to work correctly.\n",
      "- A [postcondition](glossary.html#postcondition) is something that must be true\n",
      "  at the end of a piece of code if it worked correctly.\n",
      "- An [invariant](glossary.html#invariant) is something that is always true\n",
      "  at a particular point inside a piece of code."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For example,\n",
      "suppose we are representing rectangles using a list of four coordinates `[x0, y0, x1, y1]`.\n",
      "In order to do some calculations,\n",
      "we need to normalize the rectangle so that it is at the origin\n",
      "and 1.0 units long on its longest axis.\n",
      "This function does that:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize_rectangle(rect):\n",
      "    x0, y0, x1, y1 = rect\n",
      "    assert x0 < x1, 'Invalid X coordinates'\n",
      "    assert y0 < y1, 'Invalid Y coordinates'\n",
      "\n",
      "    dx = x1 - x0\n",
      "    dy = y1 - y0\n",
      "    if dx > dy:\n",
      "        scaled = float(dy) / dx\n",
      "        upper_x, upper_y = 1.0, scaled\n",
      "    else:\n",
      "        scaled = float(dx) / dy\n",
      "        upper_x, upper_y = scaled, 1.0\n",
      "\n",
      "    assert 0 < upper_x <= 1.0, 'Calculated upper X coordinate invalid'\n",
      "    assert 0 < upper_y <= 1.0, 'Calculated upper Y coordinate invalid'\n",
      "\n",
      "    return [0, 0, upper_x, upper_y]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first two assertions check that we've been given a legal rectangle,\n",
      "while the last two check the output we're about to return to our caller.\n",
      "Strictly speaking these post-conditions are redundant:\n",
      "if the inputs and calculations are correct,\n",
      "the last two assertions should always hold.\n",
      "But those are pretty big ifs,\n",
      "and having the program check itself can save us a lot of hunting around later."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr/>\n",
      "### *Assertions and Bugs*\n",
      "\n",
      "<em>\n",
      "Another rule that good programmers follow is, \"Bugs become assertions.\"\n",
      "Whenever we fix a bug in a program,\n",
      "we should add some assertions to the program at that point to catch the bug if it reappears.\n",
      "After all,\n",
      "if we made the mistake once,\n",
      "then we (or someone else) might well make it again.\n",
      "Few things are as frustrating as\n",
      "having someone delete several carefully-crafted lines of code that fixed a subtle problem\n",
      "because they didn't realize what problem those lines were there to fix.\n",
      "</em>\n",
      "<hr/>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Handling Errors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Even when programmers are careful,\n",
      "things can still go wrong.\n",
      "Some errors have external causes,\n",
      "like missing or badly-formatted files.\n",
      "Others are internal,\n",
      "like bugs in code.\n",
      "Either way,\n",
      "most modern programming languages handle errors in more or less the same way."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with a look at how people used to do error handling.\n",
      "Back in the Dark Ages,\n",
      "programmers wrote functions to return a [status code](glossary.html#status_code)\n",
      "to indicate whether they had run correctly or not.\n",
      "This led to programs like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "params, status = read_params(param_file)\n",
      "if status != OK:\n",
      "    log.error('Failed to read', param_file)\n",
      "    sys.exit(ERROR)\n",
      "\n",
      "grid, status = read_grid(grid_file)\n",
      "if status != OK:\n",
      "    log.error('Failed to read', grid_file)\n",
      "    sys.exit(ERROR)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The two function calls are all we really want;\n",
      "the other six lines to check that files were opened and read properly,\n",
      "and to report errors and exit if not."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A lot of code is still written this way,\n",
      "but this coding style makes it hard to see the forest for the trees.\n",
      "When we're reading a program,\n",
      "we want to understand what's supposed to happen when everything works,\n",
      "and only then think about what might happen if something goes wrong.\n",
      "When the two are interleaved,\n",
      "both are harder to understand.\n",
      "The net result is that most programmers don't bother to check the status codes their functions return."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Exceptions](glossary.html#exception) allow us to separate the \"normal\" flow of control\n",
      "from the \"exceptional\" cases that arise when something goes wrong.\n",
      "Using them produces code like this,\n",
      "which is much easier to understand:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "try:\n",
      "    params = read_params(param_file)\n",
      "    grid = read_grid(grid_file)\n",
      "except:\n",
      "    log.error('Failed to read', filename)\n",
      "    sys.exit(ERROR)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We join the normal case and the error-handling code using the keywords `try` and `except`.\n",
      "These work together like `if` and `else`:\n",
      "the statements under the `try` are what should happen if everything works,\n",
      "while the statements under `except` are what the program should do if something goes wrong."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have actually seen exceptions before without knowing it,\n",
      "since by default,\n",
      "when an exception occurs,\n",
      "Python prints it out and halts our program.\n",
      "For example,\n",
      "trying to open a nonexistent file triggers a type of exception called an `IOError`,\n",
      "while an out-of-bounds index to a list triggers an `IndexError`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "open('nonexistent-file.txt', 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: 'nonexistent-file.txt'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-58cbde3dd63c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nonexistent-file.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'nonexistent-file.txt'"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "values = [0, 1, 2]\n",
      "print values[999]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-7fed13afc650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use `try` and `except` to deal with these errors ourselves\n",
      "if we don't want the program simply to fall over.\n",
      "Here,\n",
      "for example,\n",
      "we put our attempt to open a nonexistent file inside a `try`,\n",
      "and in the `except`, we print a not-very-helpful error message:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    reader = open('nonexistent-file.txt', 'r')\n",
      "except IOError:\n",
      "    print 'Whoops!'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Whoops!\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When Python executes this code,\n",
      "it runs the statement inside the `try`.\n",
      "If that works, it skips over the `except` block without running it.\n",
      "If an exception occurs inside the `try` block,\n",
      "though,\n",
      "Python compares the type of the exception to the type specified by the `except`.\n",
      "If they match, it executes the code in the `except` block."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`IOError` is Python's way of reporting several kinds of problems\n",
      "related to input and output:\n",
      "not just files that don't exist,\n",
      "but also things like not having permission to read files,\n",
      "and so on.\n",
      "We can put as many lines of code in a `try` block as we want,\n",
      "just as we can put many statements under an `if`.\n",
      "We can also handle several different kinds of errors afterward.\n",
      "For example,\n",
      "here's some code to calculate the entropy at each point in a grid:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "try:\n",
      "    params = read_params(param_file)\n",
      "    grid = read_grid(grid_file)\n",
      "    entropy = lee_entropy(params, grid)\n",
      "    write_entropy(entropy_file, entropy)\n",
      "except IOError:\n",
      "    log_error_and_exit('IO error')\n",
      "except ArithmeticError:\n",
      "    log_error_and_exit('Arithmetic error')\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Python tries to run the four functions inside the `try` as normal.\n",
      "If an error occurs in any of them,\n",
      "Python immediately jumps down\n",
      "and tries to find an `except` of the corresponding type:\n",
      "if the exception is an `IOError`,\n",
      "Python jumps into the first error handler,\n",
      "while if it's an `ArithmeticError`,\n",
      "Python jumps into the second handler instead.\n",
      "It will only execute one of these,\n",
      "just as it will only execute one branch\n",
      "of a series of `if`/`elif`/`else` statements."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This layout has made the code easier to read,\n",
      "but we've lost something important:\n",
      "the message printed out by the `IOError` branch doesn't tell us\n",
      "which file caused the problem.\n",
      "We can do better if we capture and hang on to the object that Python creates\n",
      "to record information about the error:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "try:\n",
      "    params = read_params(param_file)\n",
      "    grid = read_grid(grid_file)\n",
      "    entropy = lee_entropy(params, grid)\n",
      "    write_entropy(entropy_file, entropy)\n",
      "except IOError as err:\n",
      "    log_error_and_exit('Cannot read/write' + err.filename)\n",
      "except ArithmeticError as err:\n",
      "    log_error_and_exit(err.message)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If something goes wrong in the `try`,\n",
      "Python creates an exception object,\n",
      "fills it with information,\n",
      "and assigns it to the variable `err`.\n",
      "(There's nothing special about this variable name&mdash;we can use anything we want.)\n",
      "Exactly what information is recorded depends on what kind of error occurred;\n",
      "Python's documentation describes the properties of each type of error in detail,\n",
      "but we can always just print the exception object.\n",
      "In the case of an I/O error,\n",
      "we print out the name of the file that caused the problem.\n",
      "And in the case of an arithmetic error,\n",
      "printing out the message embedded in the exception object is what Python would have done anyway."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So much for how exceptions work:\n",
      "how should they be used?\n",
      "Some programmers use `try` and `except` to give their programs default behaviors.\n",
      "For example,\n",
      "if this code can't read the grid file that the user has asked for,\n",
      "it creates a default grid instead:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "try:\n",
      "    grid = read_grid(grid_file)\n",
      "except IOError:\n",
      "    grid = default_grid()\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other programmers would explicitly test for the grid file,\n",
      "and use `if` and `else` for control flow:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "if file_exists(grid_file):\n",
      "    grid = read_grid(grid_file)\n",
      "else:\n",
      "    grid = default_grid()\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's mostly a matter of taste,\n",
      "but we prefer the second style.\n",
      "As a rule,\n",
      "exceptions should only be used to handle exceptional cases.\n",
      "If the program knows how to fall back to a default grid,\n",
      "that's not an unexpected event.\n",
      "Using `if` and `else`\n",
      "instead of `try` and `except`\n",
      "sends different signals to anyone reading our code,\n",
      "even if they do the same thing."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Novices often ask another question about exception handling style as well,\n",
      "but before we address it,\n",
      "there's something in our example that you might not have noticed.\n",
      "Exceptions can actually be thrown a long way:\n",
      "they don't have to be handled immediately.\n",
      "Take another look at this code:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "try:\n",
      "    params = read_params(param_file)\n",
      "    grid = read_grid(grid_file)\n",
      "    entropy = lee_entropy(params, grid)\n",
      "    write_entropy(entropy_file, entropy)\n",
      "except IOError as err:\n",
      "    log_error_and_exit('Cannot read/write' + err.filename)\n",
      "except ArithmeticError as err:\n",
      "    log_error_and_exit(err.message)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The four lines in the `try` block are all function calls.\n",
      "They might catch and handle exceptions themselves,\n",
      "but if an exception occurs in one of them that *isn't* handled internally,\n",
      "Python looks in the calling code for a matching `except`.\n",
      "If it doesn't find one there,\n",
      "it looks in that function's caller,\n",
      "and so on.\n",
      "If we get all the way back to the main program without finding an exception handler,\n",
      "Python's default behavior is to print an error message like the ones we've been seeing all along."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This rule is the origin of the rule \"Throw Low, Catch High.\"\n",
      "There are many places in our program where an error might occur.\n",
      "There are only a few, though, where errors can sensibly be handled.\n",
      "For example,\n",
      "a linear algebra library doesn't know whether it's being called directly from the Python interpreter,\n",
      "or whether it's being used as a component in a larger program.\n",
      "In the latter case,\n",
      "the library doesn't know if the program that's calling it is being run from the command line or from a GUI.\n",
      "The library therefore shouldn't try to handle or report errors itself,\n",
      "because it has no way of knowing what the right way to do this is.\n",
      "It should instead just raise an exception,\n",
      "and let its caller figure out how best to handle it."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally,\n",
      "we can raise exceptions ourselves if we want to.\n",
      "In fact,\n",
      "we *should* do this,\n",
      "since it's the standard way in Python to signal that something has gone wrong.\n",
      "Here,\n",
      "for example,\n",
      "is a function that reads a grid and checks its consistency:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "def read_grid(grid_file):\n",
      "    '''Read grid, checking consistency.'''\n",
      "\n",
      "    data = read_raw_data(grid_file)\n",
      "    if not grid_consistent(data):\n",
      "        raise Exception('Inconsistent grid: ' + grid_file)\n",
      "    result = normalize_grid(data)\n",
      "\n",
      "    return result\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `raise` statement creates a new exception with a meaningful error message.\n",
      "Since `read_grid` itself doesn't contain a `try`/`except` block,\n",
      "this exception will always be thrown up and out of the function,\n",
      "to be caught and handled by whoever is calling `read_grid`.\n",
      "We can define new types of exceptions if we want to.\n",
      "And we should,\n",
      "so that errors in our code can be distinguished from errors in other people's code.\n",
      "However,\n",
      "this involves classes and objects,\n",
      "which is outside the scope of these lessons."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Unit Testing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we understand how Python manages error,\n",
      "we can return to the subject of testing.\n",
      "Most people don't enjoy writing tests,\n",
      "so if we want them to actually do it,\n",
      "it must be easy to:\n",
      "\n",
      "- add or change tests,\n",
      "- understand the tests that have already been written,\n",
      "- run those tests, and\n",
      "- understand those tests' results."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test results must also be reliable.\n",
      "If a testing tool says that code is working when it's not,\n",
      "or reports problems when there actually aren't any,\n",
      "people will lose faith in it and stop using it."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The simplest kind of test is a [unit test](glossary.html#unit_test)\n",
      "that checks the behavior of one component of a program.\n",
      "As an example,\n",
      "suppose we're testing a function called `rectangle_area`\n",
      "that returns the area of an `[x0, y0, x1, y1]` rectangle.\n",
      "We'll start by testing our code directly using `assert`.\n",
      "Here,\n",
      "we call the function three times with different arguments,\n",
      "checking that the right value is returned each time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rectangle import rectangle_area\n",
      "\n",
      "assert rectangle_area([0, 0, 1, 1]) == 1.0\n",
      "assert rectangle_area([1, 1, 4, 4]) == 9.0\n",
      "assert rectangle_area([0, 1, 4, 7]) == 24.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AssertionError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-11-ebf7f5f1c120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mrectangle_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mrectangle_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mrectangle_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m24.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mAssertionError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This result is used,\n",
      "in the sense that we know something's wrong,\n",
      "but look what happens if we run the tests in a different order:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert rectangle_area([0, 1, 4, 7]) == 24.0\n",
      "assert rectangle_area([1, 1, 4, 4]) == 9.0\n",
      "assert rectangle_area([0, 0, 1, 1]) == 1.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AssertionError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-548f3f32c981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mrectangle_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m24.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mrectangle_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mrectangle_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAssertionError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Python halts at the first failed assertion,\n",
      "so the second and third tests aren't run at all.\n",
      "It would be more helpful if we could get data from all of our tests every time they're run,\n",
      "since the more information we have,\n",
      "the faster we're likely to be able to track down bugs.\n",
      "It would also be helpful to have some kind of summary report:\n",
      "if our [test suite](glossary.html#test_suite) includes thirty or forty tests\n",
      "(as it well might for a complex function or library that's widely used),\n",
      "we'd like to know how many passed or failed."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's a different approach.\n",
      "First, let's put each test in a function with a meaningful name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_unit_square():\n",
      "    assert rectangle_area([0, 0, 1, 1]) == 1.0\n",
      "\n",
      "def test_large_square():\n",
      "    assert rectangle_area([1, 1, 4, 4]) == 9.0\n",
      "\n",
      "def test_actual_rectangle():\n",
      "    assert rectangle_area([0, 1, 4, 7]) == 24.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next,\n",
      "import a library called `ears`\n",
      "and ask it to run our tests for us:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ears\n",
      "ears.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "..f\n",
        "2 pass, 1 fail, 0 error\n",
        "----------------------------------------\n",
        "fail: test_actual_rectangle\n",
        "Traceback (most recent call last):\n",
        "  File \"ears.py\", line 43, in run\n",
        "    test()\n",
        "  File \"<ipython-input-13-643689ad0a0f>\", line 8, in test_actual_rectangle\n",
        "    assert rectangle_area([0, 1, 4, 7]) == 24.0\n",
        "AssertionError\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`ears.run` looks in the calling program\n",
      "for functions whose names start with the letters `'test_'`\n",
      "and runs each one.\n",
      "If the function complete without an assertion being triggered,\n",
      "we count the test as a [success](glossary.html#test_success).\n",
      "If an assertion fails,\n",
      "we count the test as a [failure](glossary.html#test_failure),\n",
      "but if any other exception occurs,\n",
      "we count it as an [error](glossary.html#test_error)\n",
      "because the odds are that the test itself is broken."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`ears` belongs to a family of tools called [xUnit testing library](glossary.html#xUnit).\n",
      "The name \"xUnit\" comes from the fact that\n",
      "many of them are imitations of a Java testing library called JUnit.\n",
      "The [Wikipedia page](http://en.wikipedia.org/wiki/List_of_unit_testing_frameworks) on the subject\n",
      "lists dozens of similar frameworks in almost as many languages,\n",
      "all of which have a similar structure:\n",
      "each test is a single function that follows some naming convention\n",
      "(e.g., starts with `'test_'`),\n",
      "and the framework runs them in some order\n",
      "and reports how many passed, failed, or were broken."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most unit tests aren't as simple as a single function call,\n",
      "and many include several assertions\n",
      "to check several aspects of the values that functions return.\n",
      "For example,\n",
      "suppose we have a function called `border`\n",
      "that's supposed to draw a black border around an image grid.\n",
      "Here are a couple of unit tests for it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ipythonblocks import ImageGrid\n",
      "from border import border\n",
      "\n",
      "black = (0, 0, 0)\n",
      "white = (255, 255, 255)\n",
      "\n",
      "def test_border_2x2():\n",
      "    fixture = ImageGrid(2, 2, fill=white)\n",
      "    border(fixture, black)\n",
      "    assert fixture[0, 0].rgb == black\n",
      "    assert fixture[0, 1].rgb == black\n",
      "    assert fixture[1, 0].rgb == black\n",
      "    assert fixture[1, 1].rgb == black\n",
      "\n",
      "def count_colors(grid):\n",
      "    num_black = num_white = num_other = 0\n",
      "    for x in range(grid.width):\n",
      "        for y in range(grid.height):\n",
      "            if grid[x, y].rgb == black:\n",
      "                num_black += 1\n",
      "            elif grid[x, y].rgb == white:\n",
      "                num_white += 1\n",
      "            else:\n",
      "                num_other = 0\n",
      "    return num_black, num_white, num_other\n",
      "    \n",
      "def test_border_3x3():\n",
      "    fixture = ImageGrid(3, 3, fill=white)\n",
      "    border(fixture, black)\n",
      "    num_black, num_white, num_other = count_colors(fixture)\n",
      "    assert num_black == 8\n",
      "    assert num_white == 1\n",
      "    assert num_other == 0\n",
      "    assert fixture[1, 1].rgb == white # only white cell is in the center\n",
      "        \n",
      "ears.run('test_border_')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...\n",
        "3 pass, 0 fail, 0 error\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first test checks things directly;\n",
      "the second uses a helper function to count cells of different colors,\n",
      "then checks that those counts are correct\n",
      "and that the only white cell is in the middle of the 3&times;3 grid.\n",
      "If we go on to test grids of a few other sizes,\n",
      "we can use this helper function to check them as well."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This example also demonstrates that\n",
      "writing tests can be as difficult as writing the program in the first place.\n",
      "In fact,\n",
      "if we don't build our program out of small functions that are more-or-less independent,\n",
      "writing tests can actually be *more* complicated than writing the code itself.\n",
      "Luckily,\n",
      "there's a technique to help us build things right."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Test-Driven Development"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Libraries like `ear` can't think of test cases for us.\n",
      "We still have to decide what to test and how many tests to run.\n",
      "Our best guide here is economics:\n",
      "we want the tests that are most likely to give us useful information\n",
      "that we don't already have.\n",
      "For example,\n",
      "if `rectangle_area([0, 0, 1, 1])` works,\n",
      "there's probably not much point testing `rectangle_area([0, 0, 2, 2])`,\n",
      "since it's hard to think of a bug that would show up in one case but not in the other."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should therefore try to choose tests that are as different from each other as possible,\n",
      "so that we force the code we're testing to execute in all the different ways it can.\n",
      "Another way of thinking about this is that we should try to find [boundary cases](glossary.html#boundary_case).\n",
      "If a function works for zero,\n",
      "one,\n",
      "and a million values,\n",
      "it will probably work for eighteen values."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using boundary values as tests has another advantage:\n",
      "it can help us design our software.\n",
      "To see how,\n",
      "consider this test case for our rectangle area function:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "def test_inverted_rectangle():\n",
      "    assert rectangle_area([1, 5, 5, 2]) == -12.0\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Is that test correct?\n",
      "I.e.,\n",
      "are rectangles with `x1<x0` or `y1<y0` legal,\n",
      "and do they have negative area?\n",
      "Or should the test be:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "def test_inverted_rectangle():\n",
      "    try:\n",
      "        rectangle_area([1, 5, 5, 2])\n",
      "        assert False, 'Function did not raise exception for invalid rectangle'\n",
      "    except ValueError:\n",
      "        pass # rectangle_area failed with the expected kind of exception\n",
      "    except Exception:\n",
      "        assert False, 'Function did not raise correct kind of exception for invalid rectangle'\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The logic in this second version may take a moment to work out,\n",
      "but the idea is straightforward:\n",
      "we want to check that `rectangle_area` raises a `ValueError` exception\n",
      "if it's given a rectangle whose upper edge is below or to the left of its lower edge."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's another test case that can help us design our software:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "def test_zero_width():\n",
      "    assert rectangle_area([2, 1, 2, 8]) == 0\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We might decide that rectangles with negative areas aren't allowed,\n",
      "but what about rectangles with zero area,\n",
      "i.e.,\n",
      "rectangles that are actually lines?\n",
      "Any actual implementation of `rectangle_area` will do *something* with one of these;\n",
      "writing unit tests for boundary cases is a good way to specify exactly what that something is."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unit tests are actually such a good way to define how functions ought to behave that\n",
      "many programmers use a practice called [test-driven development](glossary.html#test_driven_development) (TDD).\n",
      "Instead of writing code,\n",
      "then figuring out how to test it,\n",
      "these programmers:\n",
      "\n",
      "1. write some unit tests for a function that doesn't exist yet,\n",
      "2. write that function,\n",
      "3. modify it until it passes all of the tests, then\n",
      "4. clean up the function, i.e., make it more readable or more efficient without breaking any of the tests."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The mantra often used during TDD is \"red, green, refactor\":\n",
      "get a red light (i.e., some failing tests),\n",
      "make it turn green (i.e., get something working),\n",
      "and then clean it up by refactoring.\n",
      "This cycle should take anywhere from a couple of minutes to an hour or so.\n",
      "If it takes longer than that,\n",
      "the change being made is probably too large,\n",
      "and should be broken down into smaller (and more comprehensible) steps."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TDD's proponents argue that it helps people produce better code for two reasons.\n",
      "First,\n",
      "it encourages them to write code in small, self-contained chunks,\n",
      "and to actually write tests for those chunks.\n",
      "Second,\n",
      "it frees them from [confirmation bias](glossary.html#confirmation_bias):\n",
      "since they haven't written their function yet,\n",
      "their subconscious cannot steer their testing toward proving it correct\n",
      "rather than finding errors."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Empirical studies of TDD have had mixed results:\n",
      "some have found it beneficial,\n",
      "while others have found no effect.\n",
      "But even if you don't use it day to day,\n",
      "trying it a few times helps you learn how to design functions and programs that are easier to test."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Key Points"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Use `assert` to embed pre-conditions, post-conditions, and invariants in programs.\n",
      "- Use `raise` to signal an error, and `try`/`except` to handle errors.\n",
      "- Use a unit-testing framework to check and re-check code's correctness.\n",
      "- Put each unit test in its own small function.\n",
      "- Use test-driven development to define how functions should behave."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}